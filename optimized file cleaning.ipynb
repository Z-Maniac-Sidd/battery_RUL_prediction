{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eec82e2b-1c1a-4ffd-94f7-97b2f41956d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 files. Processing...\n",
      "\n",
      "Processing: CY25-05_1-#1.xlsx...\n",
      "Done. Saved as: Cleaned_CY25-05_1-#1.xlsx\n",
      "\n",
      "Processing: CY25-05_1-#2.xlsx...\n",
      "Done. Saved as: Cleaned_CY25-05_1-#2.xlsx\n",
      "\n",
      "Processing: CY25-05_1-#3.xlsx...\n",
      "Error processing CY25-05_1-#3.xlsx: File is not a zip file\n",
      "\n",
      "Processing: CY25-05_2-#1.xlsx...\n",
      "Done. Saved as: Cleaned_CY25-05_2-#1.xlsx\n",
      "\n",
      "Processing: CY25-05_2-#2.xlsx...\n",
      "Done. Saved as: Cleaned_CY25-05_2-#2.xlsx\n",
      "\n",
      "Processing: CY25-05_2-#3.xlsx...\n",
      "Done. Saved as: Cleaned_CY25-05_2-#3.xlsx\n",
      "\n",
      "Processing: CY25-05_4-#1.xlsx...\n",
      "Done. Saved as: Cleaned_CY25-05_4-#1.xlsx\n",
      "\n",
      "Processing: CY25-05_4-#2.xlsx...\n",
      "Done. Saved as: Cleaned_CY25-05_4-#2.xlsx\n",
      "\n",
      "Processing: CY25-05_4-#3.xlsx...\n",
      "Done. Saved as: Cleaned_CY25-05_4-#3.xlsx\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def clean_battery_data():\n",
    "    # Find all Excel files in the current directory\n",
    "    files = [f for f in os.listdir('.') if f.endswith(('.xlsx', '.xls'))]\n",
    "    \n",
    "    if not files:\n",
    "        print(\"No Excel files found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(files)} files. Processing...\\n\")\n",
    "\n",
    "    for file in files:\n",
    "        # Skip files we've already generated\n",
    "        if file.startswith(\"Cleaned_\"):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            print(f\"Processing: {file}...\")\n",
    "            \n",
    "            # Load the Excel file\n",
    "            xls = pd.ExcelFile(file)\n",
    "            processed_sheets = {}\n",
    "\n",
    "            for sheet_name in xls.sheet_names:\n",
    "                df = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "                \n",
    "                # Clean up whitespace in column names just in case\n",
    "                df.columns = df.columns.str.strip()\n",
    "\n",
    "                # --- CONFIGURATION ---\n",
    "                # Pandas handles duplicate columns by adding .1, .2, etc.\n",
    "                # Col B: 'control/V' (Original) -> We keep this for filtering\n",
    "                # Col G: 'control/V.1' (Duplicate) -> We want to delete this\n",
    "                \n",
    "                col_vol_keep = 'control/V'      # Matches Column B\n",
    "                col_current  = '<I>/mA'         # Matches Column D\n",
    "                col_ctrl_ma  = 'control/mA'     # Matches Column H\n",
    "                col_to_drop  = 'control/V.1'    # Matches Column G (The duplicate)\n",
    "\n",
    "                # --- STEP 1: Remove rows where all 3 specific columns are 0 ---\n",
    "                # We check if the necessary columns exist\n",
    "                if {col_vol_keep, col_current, col_ctrl_ma}.issubset(df.columns):\n",
    "                    \n",
    "                    # Create the filter condition (All 3 must be 0)\n",
    "                    condition_mask = (\n",
    "                        (df[col_vol_keep] == 0) & \n",
    "                        (df[col_current] == 0) & \n",
    "                        (df[col_ctrl_ma] == 0)\n",
    "                    )\n",
    "                    \n",
    "                    # Keep rows that do NOT match the condition\n",
    "                    df = df[~condition_mask]\n",
    "                else:\n",
    "                    print(f\"  - Sheet '{sheet_name}': Could not find all filter columns. Skipping row removal.\")\n",
    "\n",
    "                # --- STEP 2: Delete ONLY the duplicate column (Col G) ---\n",
    "                if col_to_drop in df.columns:\n",
    "                    df = df.drop(columns=[col_to_drop])\n",
    "                    # print(f\"  - Sheet '{sheet_name}': Dropped duplicate column '{col_to_drop}'.\")\n",
    "                \n",
    "                # Add processed dataframe to our dictionary\n",
    "                processed_sheets[sheet_name] = df\n",
    "\n",
    "            # --- STEP 3: Save to new file ---\n",
    "            output_filename = f\"Cleaned_{file}\"\n",
    "            \n",
    "            # Using openpyxl engine for .xlsx files\n",
    "            with pd.ExcelWriter(output_filename, engine='openpyxl') as writer:\n",
    "                for sheet_name, data in processed_sheets.items():\n",
    "                    data.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            \n",
    "            print(f\"Done. Saved as: {output_filename}\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    clean_battery_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d02b74c1-5ea8-49bb-9963-dfbd051cab62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 files. Processing...\n",
      "\n",
      "Processing: Cleaned_CY25-05_1-#1.xlsx...\n",
      "    - Sheet 'Sheet_1': Deleted 131905 rows where control/V == 4.1999354\n",
      "    - Sheet 'Sheet_2': Deleted 215027 rows where control/V == 4.1999354\n",
      "    - Sheet 'Sheet_3': Deleted 251356 rows where control/V == 4.1999354\n",
      "Saved: spikeremoved_Cleaned_CY25-05_1-#1.xlsx\n",
      "\n",
      "Processing: Cleaned_CY25-05_1-#2.xlsx...\n",
      "    - Sheet 'Sheet_1': Deleted 130671 rows where control/V == 4.1999354\n",
      "    - Sheet 'Sheet_2': Deleted 214404 rows where control/V == 4.1999354\n",
      "    - Sheet 'Sheet_3': Deleted 259999 rows where control/V == 4.1999354\n",
      "    - Sheet 'Sheet_4': Deleted 941 rows where control/V == 4.1999354\n",
      "Saved: spikeremoved_Cleaned_CY25-05_1-#2.xlsx\n",
      "\n",
      "Processing: Cleaned_CY25-05_2-#1.xlsx...\n",
      "    - Sheet 'Sheet_1': Deleted 156881 rows where control/V == 4.1999354\n",
      "    - Sheet 'Sheet_2': Deleted 245407 rows where control/V == 4.1999354\n",
      "    - Sheet 'Sheet_3': Deleted 227911 rows where control/V == 4.1999354\n",
      "    - Found and deleted 2 spike/outlier rows based on 'Ecell/V'.\n",
      "Saved: spikeremoved_Cleaned_CY25-05_2-#1.xlsx\n",
      "\n",
      "Processing: Cleaned_CY25-05_2-#2.xlsx...\n",
      "    - Found and deleted 76 spike/outlier rows based on 'Ecell/V'.\n",
      "    - Found and deleted 93 spike/outlier rows based on 'Ecell/V'.\n",
      "    - Found and deleted 109 spike/outlier rows based on 'Ecell/V'.\n",
      "Saved: spikeremoved_Cleaned_CY25-05_2-#2.xlsx\n",
      "\n",
      "Processing: Cleaned_CY25-05_2-#3.xlsx...\n",
      "    - Found and deleted 71 spike/outlier rows based on 'Ecell/V'.\n",
      "    - Found and deleted 87 spike/outlier rows based on 'Ecell/V'.\n",
      "    - Found and deleted 83 spike/outlier rows based on 'Ecell/V'.\n",
      "Saved: spikeremoved_Cleaned_CY25-05_2-#3.xlsx\n",
      "\n",
      "Processing: Cleaned_CY25-05_4-#1.xlsx...\n",
      "    - Found and deleted 74 spike/outlier rows based on 'Ecell/V'.\n",
      "    - Found and deleted 116 spike/outlier rows based on 'Ecell/V'.\n",
      "    - Found and deleted 84 spike/outlier rows based on 'Ecell/V'.\n",
      "Saved: spikeremoved_Cleaned_CY25-05_4-#1.xlsx\n",
      "\n",
      "Processing: Cleaned_CY25-05_4-#2.xlsx...\n",
      "    - Sheet 'Sheet_1': Deleted 157585 rows where control/V == 4.1999354\n",
      "    - Sheet 'Sheet_2': Deleted 247532 rows where control/V == 4.1999354\n",
      "    - Found and deleted 2 spike/outlier rows based on 'Ecell/V'.\n",
      "    - Sheet 'Sheet_3': Deleted 197992 rows where control/V == 4.1999354\n",
      "Saved: spikeremoved_Cleaned_CY25-05_4-#2.xlsx\n",
      "\n",
      "Processing: Cleaned_CY25-05_4-#3.xlsx...\n",
      "    - Found and deleted 71 spike/outlier rows based on 'Ecell/V'.\n",
      "    - Found and deleted 81 spike/outlier rows based on 'Ecell/V'.\n",
      "    - Found and deleted 52 spike/outlier rows based on 'Ecell/V'.\n",
      "Saved: spikeremoved_Cleaned_CY25-05_4-#3.xlsx\n",
      "\n",
      "Processing: CY25-05_4-#3.xlsx...\n",
      "    - Found and deleted 71 spike/outlier rows based on 'Ecell/V'.\n",
      "    - Found and deleted 81 spike/outlier rows based on 'Ecell/V'.\n",
      "    - Found and deleted 52 spike/outlier rows based on 'Ecell/V'.\n",
      "Saved: spikeremoved_CY25-05_4-#3.xlsx\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def delete_spike_rows(df, col_name, window=20, threshold=3):\n",
    "    \"\"\"\n",
    "    Identifies spikes using Z-score and DELETES the entire row.\n",
    "    \"\"\"\n",
    "    # Calculate Rolling Stats\n",
    "    rolling_mean = df[col_name].rolling(window=window, center=True).mean()\n",
    "    rolling_std = df[col_name].rolling(window=window, center=True).std()\n",
    "\n",
    "    # Detect Outliers (Spikes)\n",
    "    # A point is an outlier if it deviates significantly from the local average\n",
    "    is_outlier = (df[col_name] - rolling_mean).abs() > (threshold * rolling_std)\n",
    "\n",
    "    # Count how many we are dropping\n",
    "    num_outliers = is_outlier.sum()\n",
    "    \n",
    "    if num_outliers > 0:\n",
    "        # Keep only the rows that are NOT outliers\n",
    "        df_clean = df[~is_outlier].copy()\n",
    "        print(f\"    - Found and deleted {num_outliers} spike/outlier rows based on '{col_name}'.\")\n",
    "        return df_clean\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "def process_battery_data():\n",
    "    files = [f for f in os.listdir('.') if f.endswith(('.xlsx', '.xls'))]\n",
    "    \n",
    "    # Ignore output files to prevent re-processing\n",
    "    files = [f for f in files if not f.startswith(\"spikeremoved_\")]\n",
    "\n",
    "    if not files:\n",
    "        print(\"No Excel files found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(files)} files. Processing...\\n\")\n",
    "\n",
    "    for file in files:\n",
    "        try:\n",
    "            print(f\"Processing: {file}...\")\n",
    "            xls = pd.ExcelFile(file)\n",
    "            processed_sheets = {}\n",
    "\n",
    "            for sheet_name in xls.sheet_names:\n",
    "                df = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "                df.columns = df.columns.str.strip()\n",
    "\n",
    "                # --- CONFIGURATION ---\n",
    "                col_vol     = 'control/V'      # For filtering\n",
    "                col_cur     = '<I>/mA'         # For filtering 0s\n",
    "                col_ctrl_ma = 'control/mA'     # For filtering 0s\n",
    "                col_ecell   = 'Ecell/V'        # For detecting spikes\n",
    "                \n",
    "                target_val  = 4.1999354        # The exact value to remove\n",
    "\n",
    "                # 1. Remove \"All Zero\" Rows (control/V, I, control/mA are all 0)\n",
    "                if {col_vol, col_cur, col_ctrl_ma}.issubset(df.columns):\n",
    "                    condition_zeros = (\n",
    "                        (df[col_vol] == 0) & \n",
    "                        (df[col_cur] == 0) & \n",
    "                        (df[col_ctrl_ma] == 0)\n",
    "                    )\n",
    "                    df = df[~condition_zeros]\n",
    "\n",
    "                # 2. Remove rows where control/V is exactly 4.1999354\n",
    "                if col_vol in df.columns and pd.api.types.is_numeric_dtype(df[col_vol]):\n",
    "                    # We use isclose to handle floating point precision safely\n",
    "                    # This finds rows equal to 4.1999354\n",
    "                    is_target = np.isclose(df[col_vol], target_val, atol=1e-6)\n",
    "                    if is_target.sum() > 0:\n",
    "                        print(f\"    - Sheet '{sheet_name}': Deleted {is_target.sum()} rows where {col_vol} == {target_val}\")\n",
    "                        df = df[~is_target]\n",
    "\n",
    "                # 3. Delete Outlier Rows (Spikes) in Ecell/V\n",
    "                if col_ecell in df.columns:\n",
    "                    # Note: You can adjust 'threshold' (default 3) if it deletes too much/too little\n",
    "                    df = delete_spike_rows(df, col_ecell, window=20, threshold=3)\n",
    "\n",
    "                # Store the cleaned data\n",
    "                processed_sheets[sheet_name] = df\n",
    "\n",
    "            # --- Save to new file ---\n",
    "            output_filename = f\"spikeremoved_{file}\"\n",
    "            with pd.ExcelWriter(output_filename, engine='openpyxl') as writer:\n",
    "                for sheet_name, data in processed_sheets.items():\n",
    "                    data.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            \n",
    "            print(f\"Saved: {output_filename}\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_battery_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd2e9df-d244-48d2-8b46-2780a5ebba1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
